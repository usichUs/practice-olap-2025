import psycopg2
import pandas as pd
from datetime import datetime

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
DB_CONFIG = {
    'host': 'localhost',
    'port': 5432,
    'database': 'competency_analysis',
    'user': 'practice_user',
    'password': 'practice_password'
}

def get_connection():
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î"""
    try:
        return psycopg2.connect(**DB_CONFIG)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î: {e}")
        return None

def get_all_tables():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö —Ç–∞–±–ª–∏—Ü –≤ –±–∞–∑–µ"""
    conn = get_connection()
    if not conn:
        return []
    
    try:
        cur = conn.cursor()
        cur.execute("""
            SELECT table_name 
            FROM information_schema.tables 
            WHERE table_schema = 'public' 
            AND table_type = 'BASE TABLE'
            ORDER BY table_name
        """)
        tables = [row[0] for row in cur.fetchall()]
        cur.close()
        conn.close()
        return tables
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ —Ç–∞–±–ª–∏—Ü: {e}")
        return []

def show_table_summary(table_name, conn, show_samples=True, sample_count=3):
    """–ü–æ–∫–∞–∑–∞—Ç—å –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É –ø–æ —Ç–∞–±–ª–∏—Ü–µ"""
    print(f"\nüìä {table_name.upper()}:")
    print("-" * 60)
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –æ–±—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        count_query = f"SELECT COUNT(*) FROM {table_name}"
        df_count = pd.read_sql_query(count_query, conn)
        total_records = df_count.iloc[0, 0]
        
        if total_records == 0:
            print("  üì≠ –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
            return
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü—ã
        columns_query = f"""
            SELECT column_name, data_type, is_nullable
            FROM information_schema.columns 
            WHERE table_name = '{table_name}' 
            ORDER BY ordinal_position
        """
        columns_df = pd.read_sql_query(columns_query, conn)
        
        print(f"  üìà –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {total_records:,}")
        print(f"  üìã –°—Ç–æ–ª–±—Ü–æ–≤: {len(columns_df)}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É (–∫—Ä–∞—Ç–∫–æ)
        if len(columns_df) <= 8:
            column_list = list(columns_df['column_name'])
        else:
            column_list = list(columns_df['column_name'][:6]) + ['...']
        print(f"  üóÉÔ∏è  –ü–æ–ª—è: {', '.join(column_list)}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ–±—Ä–∞–∑—Ü—ã –¥–∞–Ω–Ω—ã—Ö –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if show_samples and total_records > 0:
            sample_query = f"SELECT * FROM {table_name} LIMIT {sample_count}"
            sample_df = pd.read_sql_query(sample_query, conn)
            
            print(f"\n  üìù –ü–µ—Ä–≤—ã–µ {min(sample_count, len(sample_df))} –∑–∞–ø–∏—Å–∏:")
            
            for i, row in sample_df.iterrows():
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –≤—ã–≤–æ–¥–∞
                row_dict = {}
                for col, val in row.items():
                    if pd.isna(val):
                        row_dict[col] = 'NULL'
                    elif isinstance(val, str) and len(val) > 50:
                        row_dict[col] = val[:47] + '...'
                    else:
                        row_dict[col] = val
                
                key_fields = list(row_dict.items())[:3]  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3 –ø–æ–ª—è
                print(f"    {i+1:2d}. " + " | ".join([f"{k}:{v}" for k, v in key_fields]))
            
            if total_records > sample_count:
                print(f"       ... –∏ –µ—â–µ {total_records - sample_count:,} –∑–∞–ø–∏—Å–µ–π")
                
    except Exception as e:
        print(f"  ‚ùå –û—à–∏–±–∫–∞: {e}")

def show_enhanced_analytics():
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –ø–æ –¥–∞–Ω–Ω—ã–º"""
    conn = get_connection()
    if not conn:
        return
    
    print(f"\nüìà –ê–ù–ê–õ–ò–¢–ò–ö–ê –ü–û –î–ê–ù–ù–´–ú")
    print("=" * 80)
    
    analytics_queries = {
        "üîß –¢–æ–ø-10 —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π": {
            "query": """
                SELECT technology, COUNT(*) as vacancy_count, SUM(frequency) as total_mentions
                FROM vacancy_technologies_detailed 
                GROUP BY technology 
                ORDER BY vacancy_count DESC 
                LIMIT 10
            """,
            "format": lambda row: f"{row['technology']} ({row['vacancy_count']} –≤–∞–∫–∞–Ω—Å–∏–π, {row['total_mentions']} —É–ø–æ–º–∏–Ω–∞–Ω–∏–π)"
        },
        
        "üë• –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–æ–ª–µ–π": {
            "query": """
                SELECT role, COUNT(*) as count, AVG(avg_salary) as avg_salary
                FROM vacancy_details 
                WHERE role IS NOT NULL 
                GROUP BY role 
                ORDER BY count DESC 
                LIMIT 8
            """,
            "format": lambda row: f"{row['role']}: {row['count']} –≤–∞–∫–∞–Ω—Å–∏–π (—Å—Ä. –∑–∞—Ä–ø–ª–∞—Ç–∞: {row['avg_salary']:,.0f} —Ä—É–±.)" if row['avg_salary'] else f"{row['role']}: {row['count']} –≤–∞–∫–∞–Ω—Å–∏–π"
        },
        
        "üè¢ –¢–æ–ø –∫–æ–º–ø–∞–Ω–∏–∏": {
            "query": """
                SELECT company, COUNT(*) as vacancy_count, AVG(avg_salary) as avg_salary
                FROM vacancy_details 
                WHERE company IS NOT NULL 
                GROUP BY company 
                ORDER BY vacancy_count DESC 
                LIMIT 10
            """,
            "format": lambda row: f"{row['company']}: {row['vacancy_count']} –≤–∞–∫–∞–Ω—Å–∏–π"
        },
        
        "üìö –§–ì–û–° –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –ø–æ —Ç–∏–ø–∞–º": {
            "query": """
                SELECT competency_type, COUNT(*) as count
                FROM fgos_competencies
                WHERE competency_type IS NOT NULL
                GROUP BY competency_type
                ORDER BY count DESC
            """,
            "format": lambda row: f"{row['competency_type']}: {row['count']} –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π"
        },
        
        "üíº –ü—Ä–æ—Ñ—Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã –ø–æ –∫–æ–¥–∞–º": {
            "query": """
                SELECT standard_code, COUNT(*) as otf_count
                FROM otf_td_standards
                GROUP BY standard_code
                ORDER BY otf_count DESC
            """,
            "format": lambda row: f"{row['standard_code']}: {row['otf_count']} –û–¢–§/–¢–î"
        },
        
        "üîó –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ —Å –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—è–º–∏ –§–ì–û–°": {
            "query": """
                SELECT 
                    COUNT(*) as total_tech_records,
                    COUNT(CASE WHEN fgos_competencies IS NOT NULL THEN 1 END) as with_fgos,
                    ROUND(COUNT(CASE WHEN fgos_competencies IS NOT NULL THEN 1 END) * 100.0 / COUNT(*), 1) as fgos_coverage
                FROM vacancy_technologies_detailed
            """,
            "format": lambda row: f"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {row['total_tech_records']}, —Å –§–ì–û–°: {row['with_fgos']} ({row['fgos_coverage']}%)"
        },
        
        "üîó –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ —Å –ø—Ä–æ—Ñ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º–∏": {
            "query": """
                SELECT 
                    COUNT(*) as total_tech_records,
                    COUNT(CASE WHEN prof_standards IS NOT NULL THEN 1 END) as with_prof,
                    ROUND(COUNT(CASE WHEN prof_standards IS NOT NULL THEN 1 END) * 100.0 / COUNT(*), 1) as prof_coverage
                FROM vacancy_technologies_detailed
            """,
            "format": lambda row: f"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {row['total_tech_records']}, —Å –ø—Ä–æ—Ñ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º–∏: {row['with_prof']} ({row['prof_coverage']}%)"
        }
    }
    
    for title, query_info in analytics_queries.items():
        print(f"\n{title}:")
        print("-" * 50)
        
        try:
            df = pd.read_sql_query(query_info["query"], conn)
            
            if len(df) == 0:
                print("  üì≠ –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
            else:
                for i, row in df.iterrows():
                    formatted_line = query_info["format"](row)
                    print(f"  {i+1:2d}. {formatted_line}")
                    
        except Exception as e:
            print(f"  ‚ùå –û—à–∏–±–∫–∞: {e}")
    
    conn.close()

def show_olap_readiness():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –∫ OLAP –∞–Ω–∞–ª–∏–∑—É"""
    conn = get_connection()
    if not conn:
        return
    
    print(f"\nüéØ –ì–û–¢–û–í–ù–û–°–¢–¨ –ö OLAP –ê–ù–ê–õ–ò–ó–£")
    print("=" * 80)
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è
        cur = conn.cursor()
        cur.execute("""
            SELECT table_name 
            FROM information_schema.views 
            WHERE table_schema = 'public'
            ORDER BY table_name
        """)
        views = [row[0] for row in cur.fetchall()]
        
        expected_views = ['olap_competency_analysis', 'tech_market_summary', 'role_tech_salary_cube']
        
        print("üìä OLAP –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è:")
        for view in expected_views:
            if view in views:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
                cur.execute(f"SELECT COUNT(*) FROM {view}")
                count = cur.fetchone()[0]
                print(f"  ‚úÖ {view}: {count:,} –∑–∞–ø–∏—Å–µ–π")
            else:
                print(f"  ‚ùå {view}: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å CUBE –∑–∞–ø—Ä–æ—Å–æ–≤
        print(f"\nüßä –¢–µ—Å—Ç GROUP BY CUBE:")
        try:
            cur.execute("""
                SELECT 
                    role, 
                    tech_category,
                    COUNT(*) as count
                FROM olap_competency_analysis 
                WHERE role IS NOT NULL AND tech_category IS NOT NULL
                GROUP BY CUBE(role, tech_category)
                LIMIT 5
            """)
            cube_results = cur.fetchall()
            print(f"  ‚úÖ GROUP BY CUBE —Ä–∞–±–æ—Ç–∞–µ—Ç ({len(cube_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤)")
        except Exception as e:
            print(f"  ‚ùå GROUP BY CUBE: {e}")
        
        cur.close()
        conn.close()
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ OLAP: {e}")

def show_data_quality_report():
    """–û—Ç—á–µ—Ç –æ –∫–∞—á–µ—Å—Ç–≤–µ –¥–∞–Ω–Ω—ã—Ö"""
    conn = get_connection()
    if not conn:
        return
    
    print(f"\nüîç –û–¢–ß–ï–¢ –û –ö–ê–ß–ï–°–¢–í–ï –î–ê–ù–ù–´–•")
    print("=" * 80)
    
    quality_checks = [
        {
            "name": "–í–∞–∫–∞–Ω—Å–∏–∏ —Å –∑–∞—Ä–ø–ª–∞—Ç–∞–º–∏",
            "query": """
                SELECT 
                    COUNT(*) as total,
                    COUNT(avg_salary) as with_salary,
                    ROUND(COUNT(avg_salary) * 100.0 / COUNT(*), 1) as percentage
                FROM vacancy_details
            """,
            "format": lambda row: f"–í—Å–µ–≥–æ: {row['total']}, —Å –∑–∞—Ä–ø–ª–∞—Ç–æ–π: {row['with_salary']} ({row['percentage']}%)"
        },
        {
            "name": "–í–∞–∫–∞–Ω—Å–∏–∏ —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º–∏ —Ä–æ–ª—è–º–∏",
            "query": """
                SELECT 
                    COUNT(*) as total,
                    COUNT(role) as with_role,
                    ROUND(COUNT(role) * 100.0 / COUNT(*), 1) as percentage
                FROM vacancy_details
            """,
            "format": lambda row: f"–í—Å–µ–≥–æ: {row['total']}, —Å —Ä–æ–ª—å—é: {row['with_role']} ({row['percentage']}%)"
        },
        {
            "name": "–°–≤—è–∑–∞–Ω–Ω–æ—Å—Ç—å —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π",
            "query": """
                SELECT 
                    COUNT(DISTINCT vtd.technology) as unique_technologies,
                    COUNT(*) as total_technology_records,
                    ROUND(COUNT(*) * 1.0 / COUNT(DISTINCT vtd.vacancy_id), 1) as avg_tech_per_vacancy
                FROM vacancy_technologies_detailed vtd
            """,
            "format": lambda row: f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π: {row['unique_technologies']}, –≤ —Å—Ä–µ–¥–Ω–µ–º {row['avg_tech_per_vacancy']} –Ω–∞ –≤–∞–∫–∞–Ω—Å–∏—é"
        },
        {
            "name": "–ü–æ–∫—Ä—ã—Ç–∏–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—è–º–∏",
            "query": """
                SELECT 
                    COUNT(DISTINCT technology) as total_technologies,
                    COUNT(DISTINCT CASE WHEN fgos_competencies IS NOT NULL THEN technology END) as with_fgos,
                    COUNT(DISTINCT CASE WHEN prof_standards IS NOT NULL THEN technology END) as with_prof
                FROM vacancy_technologies_detailed
            """,
            "format": lambda row: f"–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–π: {row['total_technologies']}, —Å –§–ì–û–°: {row['with_fgos']}, —Å –ø—Ä–æ—Ñ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º–∏: {row['with_prof']}"
        }
    ]
    
    for check in quality_checks:
        try:
            df = pd.read_sql_query(check["query"], conn)
            if len(df) > 0:
                result = check["format"](df.iloc[0])
                print(f"  ‚úÖ {check['name']}: {result}")
        except Exception as e:
            print(f"  ‚ùå {check['name']}: –û—à–∏–±–∫–∞ - {e}")
    
    conn.close()

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å –º–µ–Ω—é"""
    print("üöÄ –ü–†–û–í–ï–†–ö–ê –§–ò–ù–ê–õ–¨–ù–´–• –î–ê–ù–ù–´–• –î–õ–Ø OLAP")
    print(f"‚è∞ –í—Ä–µ–º—è –∑–∞–ø—É—Å–∫–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ç–∞–±–ª–∏—Ü
    tables = get_all_tables()
    
    if not tables:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Ç–∞–±–ª–∏—Ü")
        return
    
    print(f"üìö –ù–∞–π–¥–µ–Ω–æ —Ç–∞–±–ª–∏—Ü: {len(tables)}")
    
    # –ê–∫—Ç—É–∞–ª—å–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è OLAP
    final_tables = ['fgos_competencies', 'otf_td_standards', 'vacancy_details', 'vacancy_technologies_detailed']
    other_tables = [t for t in tables if t not in final_tables]
    
    conn = get_connection()
    if not conn:
        return
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã
    print(f"\nüéØ –§–ò–ù–ê–õ–¨–ù–´–ï –¢–ê–ë–õ–ò–¶–´ –î–õ–Ø OLAP:")
    for table in final_tables:
        if table in tables:
            show_table_summary(table, conn, show_samples=True, sample_count=3)
        else:
            print(f"\n‚ùå {table.upper()}: –û–¢–°–£–¢–°–¢–í–£–ï–¢")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã –µ—Å–ª–∏ –µ—Å—Ç—å
    if other_tables:
        print(f"\nüìã –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –¢–ê–ë–õ–ò–¶–´:")
        for table in other_tables:
            show_table_summary(table, conn, show_samples=False)
    
    conn.close()
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∞–Ω–∞–ª–∏—Ç–∏–∫—É
    show_enhanced_analytics()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ OLAP
    show_olap_readiness()
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Ç—á–µ—Ç –æ –∫–∞—á–µ—Å—Ç–≤–µ
    show_data_quality_report()
    
    print(f"\n‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")

if __name__ == "__main__":
    main()